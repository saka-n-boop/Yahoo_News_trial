# -*- coding: utf-8 -*-
"""
çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒˆãƒ¨ã‚¿ç‰ˆï¼‰ - æœ€çµ‚è¨­å®šãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼š
1. Yahooã‚·ãƒ¼ãƒˆã«è¨˜äº‹ãƒªã‚¹ãƒˆã‚’è¿½è¨˜ã—ã€æŠ•ç¨¿æ—¥ã®å¤ã„é †ã«ä¸¦ã³æ›¿ãˆ (A-Dåˆ—)ã€‚
2. Yahooã‚·ãƒ¼ãƒˆã®E-Iåˆ—ã«å¯¾ã—ã€æœ¬æ–‡ã€ã‚³ãƒ¡ãƒ³ãƒˆæ•°ã€Geminiåˆ†æã‚’å®Ÿè¡Œã—ã€ç©ºæ¬„ãŒã‚ã‚Œã°æ›´æ–°ã€‚
"""

import os
import json
import time
import re
import random
from datetime import datetime, timedelta, timezone
from typing import List, Tuple, Optional, Set, Dict, Any

import gspread
from oauth2client.service_account import ServiceAccountCredentials
from bs4 import BeautifulSoup
import requests

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
# WebDriverWait é–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆå®‰å®šæ€§å‘ä¸Šã®ãŸã‚ï¼‰
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By

# --- Gemini API é–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
from google import genai
from google.genai import types
from google.api_core.exceptions import ResourceExhausted 
# ------------------------------------

# ====== è¨­å®š ======
# â˜…æŒ‡å®šã•ã‚ŒãŸã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDã‚’ä½¿ç”¨
SHARED_SPREADSHEET_ID = "1Ru2DT_zzKjTJptchWJitCb67VoffImGhgeOVjwlKukc"
KEYWORD = "ãƒˆãƒ¨ã‚¿"
SOURCE_SPREADSHEET_ID = SHARED_SPREADSHEET_ID
SOURCE_SHEET_NAME = "Yahoo"
DEST_SPREADSHEET_ID = SHARED_SPREADSHEET_ID
# æ–°ã—ã„ãƒ˜ãƒƒãƒ€ãƒ¼æ§‹æˆ
YAHOO_SHEET_HEADERS = ["URL", "ã‚¿ã‚¤ãƒˆãƒ«", "æŠ•ç¨¿æ—¥æ™‚", "ã‚½ãƒ¼ã‚¹", "æœ¬æ–‡", "ã‚³ãƒ¡ãƒ³ãƒˆæ•°", "ãƒã‚¸ãƒã‚¬åˆ†é¡", "ã‚«ãƒ†ã‚´ãƒªåˆ†é¡", "é–¢é€£åº¦"]
MAX_BODY_PAGES = 1
REQ_HEADERS = {"User-Agent": "Mozilla/5.0"}
TZ_JST = timezone(timedelta(hours=9))

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®æŒ‡å®š
PROMPT_FILES = [
Â  Â  "prompt_gemini_role.txt",
Â  Â  "prompt_posinega.txt",
Â  Â  "prompt_category.txt",
Â  Â  "prompt_score.txt"
]

# --- Gemini ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ– ---
try:
Â  Â  GEMINI_CLIENT = genai.Client()
except Exception as e:
Â  Â  print(f"è­¦å‘Š: Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚Geminiåˆ†æã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚ã‚¨ãƒ©ãƒ¼: {e}")
Â  Â  GEMINI_CLIENT = None
# ------------------------------------

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä¿æŒ
GEMINI_PROMPT_TEMPLATE = None

# ====== ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ç¾¤ ======

def jst_now() -> datetime:
Â  Â  return datetime.now(TZ_JST)

def format_datetime(dt_obj) -> str:
Â  Â  return dt_obj.strftime("%y/%m/%d %H:%M")

def parse_post_date(raw, today_jst: datetime) -> Optional[datetime]:
Â  Â  if raw is None: return None
Â  Â  if isinstance(raw, str):
Â  Â  Â  Â  s = raw.strip()
Â  Â  Â  Â  s = re.sub(r"\([æœˆç«æ°´æœ¨é‡‘åœŸæ—¥]\)$", "", s).strip()
Â  Â  Â  Â  s = s.strip()
Â  Â  Â  Â  for fmt in ("%y/%m/%d %H:%M", "%m/%d %H:%M", "%Y/%m/%d %H:%M", "%Y/%m/%d %H:%M:%S"):
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  dt = datetime.strptime(s, fmt)
Â  Â  Â  Â  Â  Â  Â  Â  if fmt == "%m/%d %H:%M":
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  dt = dt.replace(year=today_jst.year)
Â  Â  Â  Â  Â  Â  Â  Â  return dt.replace(tzinfo=TZ_JST)
Â  Â  Â  Â  Â  Â  except ValueError:
Â  Â  Â  Â  Â  Â  Â  Â  pass
Â  Â  Â  Â  Â  Â  return None

def build_gspread_client() -> gspread.Client:
Â  Â  """ GCP_SERVICE_ACCOUNT_KEYç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨ã—ã¦èªè¨¼ """
Â  Â  try:
Â  Â  Â  Â  creds_str = os.environ.get("GCP_SERVICE_ACCOUNT_KEY")
Â  Â  Â  Â  scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
Â  Â  Â  Â Â 
Â  Â  Â  Â  if creds_str:
Â  Â  Â  Â  Â  Â  info = json.loads(creds_str)
Â  Â  Â  Â  Â  Â  credentials = ServiceAccountCredentials.from_json_keyfile_dict(info, scope)
Â  Â  Â  Â  Â  Â  return gspread.authorize(credentials)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  raise RuntimeError("Googleèªè¨¼æƒ…å ± (GCP_SERVICE_ACCOUNT_KEY) ãŒç’°å¢ƒå¤‰æ•°ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

Â  Â  except Exception as e:
Â  Â  Â  Â  raise RuntimeError(f"Googleèªè¨¼ã«å¤±æ•—: {e}")

def load_gemini_prompt() -> str:
Â  Â  """ 4ã¤ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’çµåˆã—ã¦è¿”ã™ """
Â  Â  global GEMINI_PROMPT_TEMPLATE
Â  Â  if GEMINI_PROMPT_TEMPLATE is not None:
Â  Â  Â  Â  return GEMINI_PROMPT_TEMPLATE
Â  Â  Â  Â Â 
Â  Â  combined_instructions = []
Â  Â Â 
Â  Â  try:
Â  Â  Â  Â  script_dir = os.path.dirname(os.path.abspath(__file__))
Â  Â  Â  Â Â 
Â  Â  Â  Â  # 1. ãƒ­ãƒ¼ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« (prompt_gemini_role.txt) ã‚’æœ€åˆã«èª­ã¿è¾¼ã‚€
Â  Â  Â  Â  role_file = PROMPT_FILES[0]
Â  Â  Â  Â  file_path = os.path.join(script_dir, role_file)
Â  Â  Â  Â  with open(file_path, 'r', encoding='utf-8') as f:
Â  Â  Â  Â  Â  Â  role_instruction = f.read().strip()
Â  Â  Â  Â Â 
Â  Â  Â  Â  # 2. æ®‹ã‚Šã®åˆ†é¡ãƒ«ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
Â  Â  Â  Â  for filename in PROMPT_FILES[1:]:
Â  Â  Â  Â  Â  Â  file_path = os.path.join(script_dir, filename)
Â  Â  Â  Â  Â  Â  with open(file_path, 'r', encoding='utf-8') as f:
Â  Â  Â  Â  Â  Â  Â  Â  content = f.read().strip()
Â  Â  Â  Â  Â  Â  Â  Â  if content:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  combined_instructions.append(content)
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  if not role_instruction or not combined_instructions:
Â  Â  Â  Â  Â  Â  print("è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ãŒä¸å®Œå…¨ã¾ãŸã¯ç©ºã§ã™ã€‚")
Â  Â  Â  Â  Â  Â  return ""

Â  Â  Â  Â  # å…¨ä½“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
Â  Â  Â  Â  base_prompt = role_instruction + "\n" + "\n".join(combined_instructions)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # è¨˜äº‹æœ¬æ–‡ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’è¿½åŠ 
Â  Â  Â  Â  base_prompt += "\n\nè¨˜äº‹æœ¬æ–‡:\n{TEXT_TO_ANALYZE}"

Â  Â  Â  Â  GEMINI_PROMPT_TEMPLATE = base_prompt
Â  Â  Â  Â  print(f" Geminiãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ {PROMPT_FILES} ã‹ã‚‰èª­ã¿è¾¼ã¿ã€çµåˆã—ã¾ã—ãŸã€‚")
Â  Â  Â  Â  return base_prompt
Â  Â  Â  Â Â 
Â  Â  except FileNotFoundError as e:
Â  Â  Â  Â  print(f"è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€éƒ¨ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«å: {e.filename}")
Â  Â  Â  Â  return ""
Â  Â  except Exception as e:
Â  Â  Â  Â  print(f"è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
Â  Â  Â  Â  return ""

# ====== Gemini åˆ†æé–¢æ•° ======

def analyze_with_gemini(text_to_analyze: str) -> Tuple[str, str, str]:
Â  Â  if not GEMINI_CLIENT:
Â  Â  Â  Â  return "N/A", "N/A", "0"
Â  Â  Â  Â Â 
Â  Â  if not text_to_analyze.strip():
Â  Â  Â  Â  return "N/A", "N/A", "0"

Â  Â  prompt_template = load_gemini_prompt()
Â  Â  if not prompt_template:
Â  Â  Â  Â  return "ERROR(Prompt Missing)", "ERROR", "0"

Â  Â  MAX_RETRIES = 3 
Â  Â  # â˜…â˜…â˜… ä¿®æ­£ç®‡æ‰€: æœ€å¤§æ–‡å­—æ•°ã‚’15000ã«è¨­å®š â˜…â˜…â˜…
Â  Â  MAX_CHARACTERS = 15000 
Â  Â  # ------------------------------------------

Â  Â  for attempt in range(MAX_RETRIES):
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  # è¨˜äº‹æœ¬æ–‡ã‚’æŒ‡å®šæ–‡å­—æ•°ã«åˆ¶é™
Â  Â  Â  Â  Â  Â  text_for_prompt = text_to_analyze[:MAX_CHARACTERS]
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  prompt = prompt_template.replace("{KEYWORD}", KEYWORD)
Â  Â  Â  Â  Â  Â  prompt = prompt.replace("{TEXT_TO_ANALYZE}", text_for_prompt)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  response = GEMINI_CLIENT.models.generate_content(
Â  Â  Â  Â  Â  Â  Â  Â  model='gemini-2.5-flash',
Â  Â  Â  Â  Â  Â  Â  Â  contents=prompt,
Â  Â  Â  Â  Â  Â  Â  Â  config=types.GenerateContentConfig(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  response_mime_type="application/json",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  response_schema={"type": "object", "properties": {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "sentiment": {"type": "string", "description": "ãƒã‚¸ãƒ†ã‚£ãƒ–ã€ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ã€ãƒã‚¬ãƒ†ã‚£ãƒ–ã®ã„ãšã‚Œã‹"},Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "category": {"type": "string", "description": "ä¼æ¥­ã€ãƒ¢ãƒ‡ãƒ«ã€æŠ€è¡“ãªã©ã®åˆ†é¡çµæœ"},Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "relevance": {"type": "integer", "description": f"{KEYWORD}ã¨ã®é–¢é€£åº¦ã‚’0ã‹ã‚‰100ã®æ•´æ•°"}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }}
Â  Â  Â  Â  Â  Â  Â  Â  ),
Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â  Â  Â  analysis = json.loads(response.text.strip())
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  sentiment = analysis.get("sentiment", "N/A")
Â  Â  Â  Â  Â  Â  category = analysis.get("category", "N/A")
Â  Â  Â  Â  Â  Â  relevance = str(analysis.get("relevance", "0"))

Â  Â  Â  Â  Â  Â  return sentiment, category, relevance

Â  Â  Â  Â  except ResourceExhausted as e:
Â  Â  Â  Â  Â  Â  # ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã‚¨ãƒ©ãƒ¼ã®å ´åˆã€ãƒªãƒˆãƒ©ã‚¤ã›ãšã«çµ‚äº†
Â  Â  Â  Â  Â  Â  print(f"  ğŸš¨ Gemini API ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã‚¨ãƒ©ãƒ¼ (429): {e}")
Â  Â  Â  Â  Â  Â  return "ERROR(Quota)", "ERROR", "0"

Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  if attempt < MAX_RETRIES - 1:
Â  Â  Â  Â  Â  Â  Â  Â  wait_time = 2 ** attempt + random.random()
Â  Â  Â  Â  Â  Â  Â  Â  print(f"  âš ï¸ Gemini API ä¸€æ™‚çš„ãªã‚¨ãƒ©ãƒ¼ã€‚{wait_time:.2f} ç§’å¾…æ©Ÿã—ã¦ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™ (è©¦è¡Œ {attempt + 1}/{MAX_RETRIES})ã€‚")
Â  Â  Â  Â  Â  Â  Â  Â  time.sleep(wait_time)
Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  print(f"Geminiåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
Â  Â  Â  Â  Â  Â  Â  Â  return "ERROR", "ERROR", "0"
Â  Â  return "ERROR", "ERROR", "0"

# ====== ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•° ======

def get_yahoo_news_with_selenium(keyword: str) -> list[dict]:
Â  Â  # A-Dåˆ—ï¼ˆURL, ã‚¿ã‚¤ãƒˆãƒ«, æŠ•ç¨¿æ—¥æ™‚, ã‚½ãƒ¼ã‚¹ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
Â  Â  print("Â  Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢é–‹å§‹...")
Â  Â  options = Options()
Â  Â  options.add_argument("--headless=new")Â 
Â  Â  options.add_argument("--disable-gpu")
Â  Â  options.add_argument("--no-sandbox")
Â  Â  options.add_argument("--window-size=1280,1024")
Â  Â  options.add_argument("--disable-dev-shm-usage")
Â  Â  options.add_argument(f"user-agent={REQ_HEADERS['User-Agent']}")
Â  Â Â 
Â  Â  try:
Â  Â  Â  Â  driver_path = ChromeDriverManager().install()
Â  Â  Â  Â  service = Service(driver_path)
Â  Â  Â  Â  driver = webdriver.Chrome(service=service, options=options)
Â  Â  except Exception as e:
Â  Â  Â  Â  print(f" WebDriverã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
Â  Â  Â  Â  return []
Â  Â  Â  Â Â 
Â  Â  search_url = f"https://news.yahoo.co.jp/search?p={keyword}&ei=utf-8&categories=domestic,world,business,it,science,life,local"
Â  Â  driver.get(search_url)
Â  Â  
Â  Â  # è¨˜äº‹ãƒªã‚¹ãƒˆãŒè¡¨ç¤ºã•ã‚Œã‚‹ã¾ã§æœ€å¤§10ç§’å¾…æ©Ÿã™ã‚‹å‡¦ç†ã‚’è¿½åŠ  (å®‰å®šæ€§å‘ä¸Š)
Â  Â  try:
Â  Â  Â  Â  # æœ€æ–°ã®ã‚¯ãƒ©ã‚¹å 'sc-1u4589e-0' ã‚’å«ã‚€è¦ç´ ãŒå‡ºç¾ã™ã‚‹ã¾ã§å¾…æ©Ÿ
Â  Â  Â  Â  WebDriverWait(driver, 10).until(
Â  Â  Â  Â  Â  Â  EC.presence_of_element_located((By.CSS_SELECTOR, "li[class*='sc-1u4589e-0']"))
Â  Â  Â  Â  )
Â  Â  Â  Â  print("  è¨˜äº‹ãƒªã‚¹ãƒˆè¦ç´ ã®èª­ã¿è¾¼ã¿ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚")
Â  Â  except Exception:
Â  Â  Â  Â  print("  è­¦å‘Š: è¨˜äº‹ãƒªã‚¹ãƒˆè¦ç´ ã®è¡¨ç¤ºã«æ™‚é–“ãŒã‹ã‹ã£ã¦ã„ã¾ã™ã€‚5ç§’å¾…æ©Ÿã—ã¾ã™ã€‚")
Â  Â  Â  Â  time.sleep(5) # å¾…æ©Ÿå¤±æ•—ã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
Â  Â Â 
Â  Â  soup = BeautifulSoup(driver.page_source, "html.parser")
Â  Â  driver.quit()
Â  Â Â 
Â  Â  # â˜…â˜…â˜… ä¿®æ­£æ¸ˆã¿: è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒŠã®ã‚»ãƒ¬ã‚¯ã‚¿ã‚’æœ€æ–°ã®æ§‹é€ ã«çµ±ä¸€ â˜…â˜…â˜…
Â  Â  articles = soup.find_all("li", class_=re.compile("sc-1u4589e-0"))
Â  Â  # -----------------------------------------------------

Â  Â  articles_data = []
Â  Â Â 
Â  Â  for article in articles:
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  # ã‚¿ã‚¤ãƒˆãƒ«ã¯ div.sc-3ls169-0 ã®å­è¦ç´ ã¨ã—ã¦å–å¾—
Â  Â  Â  Â  Â  Â  title_tag = article.find("div", class_=re.compile("sc-3ls169-0"))
Â  Â  Â  Â  Â  Â  title = title_tag.text.strip() if title_tag else ""
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  link_tag = article.find("a", href=True)
Â  Â  Â  Â  Â  Â  url = link_tag["href"] if link_tag and link_tag["href"].startswith("https://news.yahoo.co.jp/articles/") else ""
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # æŠ•ç¨¿æ—¥æ™‚ã®å–å¾—ãƒ­ã‚¸ãƒƒã‚¯
Â  Â  Â  Â  Â  Â  time_tag = article.find("time")
Â  Â  Â  Â  Â  Â  # timeã‚¿ã‚°ãŒç›´æ¥è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆã€ã‚½ãƒ¼ã‚¹/æ—¥ä»˜ã®ã‚³ãƒ³ãƒ†ãƒŠã‚¯ãƒ©ã‚¹ã‚’æ¤œç´¢ã—ã¦å†æ¤œç´¢
Â  Â  Â  Â  Â  Â  if not time_tag:
Â  Â  Â  Â  Â  Â  Â  Â  source_container = article.find("div", class_=re.compile("sc-n3vj8g-0"))
Â  Â  Â  Â  Â  Â  Â  Â  if source_container:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  time_tag = source_container.find("time") 
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  date_str = time_tag.text.strip() if time_tag else ""
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # ã‚½ãƒ¼ã‚¹ã®å–å¾—ãƒ­ã‚¸ãƒƒã‚¯
Â  Â  Â  Â  Â  Â  source_text = ""
Â  Â  Â  Â  Â  Â  # ã‚¯ãƒ©ã‚¹å 'sc-n3vj8g-0' ã¨ 'sc-110wjhy-8' ã‚’ä½¿ç”¨ã—ã¦å–å¾—
Â  Â  Â  Â  Â  Â  source_container = article.find("div", class_=re.compile("sc-n3vj8g-0"))
Â  Â  Â  Â  Â  Â  if source_container:
Â  Â  Â  Â  Â  Â  Â  Â  inner = source_container.find("div", class_=re.compile("sc-110wjhy-8"))
Â  Â  Â  Â  Â  Â  Â  Â  if inner and inner.span:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # inner.spanãŒæœ€åˆã®è¦ç´ ï¼ˆã‚½ãƒ¼ã‚¹åï¼‰ã§ã‚ã‚‹ã“ã¨ã‚’åˆ©ç”¨
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  candidate_span = inner.find('span') 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if candidate_span:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  candidate = candidate_span.text.strip()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # ã‚³ãƒ¡ãƒ³ãƒˆæ•°ã‚¢ã‚¤ã‚³ãƒ³(æ•°å­—)ã§ãªã„ã“ã¨ã‚’ç¢ºèª
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not candidate.isdigit():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  source_text = candidate

Â  Â  Â  Â  Â  Â  if title and url:
Â  Â  Â  Â  Â  Â  Â  Â  formatted_date = ""
Â  Â  Â  Â  Â  Â  Â  Â  if date_str:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  date_str_clean = re.sub(r"\([æœˆç«æ°´æœ¨é‡‘åœŸæ—¥]\)$", "", date_str).strip()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  dt_obj = parse_post_date(date_str_clean, jst_now())
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if dt_obj:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  formatted_date = format_datetime(dt_obj)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  formatted_date = date_str

Â  Â  Â  Â  Â  Â  Â  Â  articles_data.append({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "URL": url,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "ã‚¿ã‚¤ãƒˆãƒ«": title,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "æŠ•ç¨¿æ—¥æ™‚": formatted_date if formatted_date else "å–å¾—ä¸å¯",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "ã‚½ãƒ¼ã‚¹": source_text
Â  Â  Â  Â  Â  Â  Â  Â  })
Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â Â 
Â  Â  print(f" Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ä»¶æ•°: {len(articles_data)} ä»¶å–å¾—")
Â  Â  return articles_data

def fetch_article_body_and_comments(base_url: str) -> Tuple[str, int]:
Â  Â  """ è¨˜äº‹æœ¬æ–‡ã¨ã‚³ãƒ¡ãƒ³ãƒˆæ•°ã‚’å–å¾—ã™ã‚‹ """
Â  Â  body_text = ""
Â  Â  comment_count = 0
Â  Â Â 
Â  Â  try:
Â  Â  Â  Â  res = requests.get(base_url, headers=REQ_HEADERS, timeout=20)
Â  Â  Â  Â  res.raise_for_status()
Â  Â  Â  Â  soup = BeautifulSoup(res.text, "html.parser")
Â  Â  Â  Â Â 
Â  Â  Â  Â  # è¨˜äº‹æœ¬æ–‡ã®å–å¾—
Â  Â  Â  Â  article = soup.find("article")
Â  Â  Â  Â  if article:
Â  Â  Â  Â  Â  Â  ps = article.find_all("p")
Â  Â  Â  Â  Â  Â  body_text = "\n".join(p.get_text(strip=True) for p in ps if p.get_text(strip=True))
Â  Â  Â  Â Â 
Â  Â  Â  Â  # ã‚³ãƒ¡ãƒ³ãƒˆæ•°ã®å–å¾—
Â  Â  Â  Â  comment_button = soup.find("button", attrs={"data-cl-params": re.compile(r"cmtmod")})
Â  Â  Â  Â Â 
Â  Â  Â  Â  if comment_button:
Â  Â  Â  Â  Â  Â  # riff-VisuallyHidden__root ã‚¯ãƒ©ã‚¹ã‚’æŒã¤éš ã—è¦ç´ ã‚’æ¢ã™ï¼ˆä¾‹: "ã‚³ãƒ¡ãƒ³ãƒˆ54ä»¶"ï¼‰
Â  Â  Â  Â  Â  Â  hidden_div = comment_button.find("div", class_="riff-VisuallyHidden__root")
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if hidden_div:
Â  Â  Â  Â  Â  Â  Â  Â  text = hidden_div.get_text(strip=True).replace(",", "")
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  # éš ã—è¦ç´ ãŒãªã„å ´åˆã¯ã€ã‚³ãƒ¡ãƒ³ãƒˆãƒœã‚¿ãƒ³å…¨ä½“ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è©¦ã™
Â  Â  Â  Â  Â  Â  Â  Â  text = comment_button.get_text(strip=True).replace(",", "")
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ•°å­—(\d+)éƒ¨åˆ†ã ã‘ã‚’æŠ½å‡º
Â  Â  Â  Â  Â  Â  match = re.search(r'(\d+)', text)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if match:
Â  Â  Â  Â  Â  Â  Â  Â  comment_count = int(match.group(1))
Â  Â  Â  Â Â 
Â  Â  except Exception as e:
Â  Â  Â  Â  print(f"Â  Â  ! è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
Â  Â  Â  Â Â 
Â  Â  return body_text, comment_count


# ====== ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ“ä½œé–¢æ•° ======

def ensure_source_sheet_headers(sh: gspread.Spreadsheet) -> gspread.Worksheet:
Â  Â  """ Yahooã‚·ãƒ¼ãƒˆã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä¿è¨¼ã™ã‚‹ """
Â  Â  try:
Â  Â  Â  Â  ws = sh.worksheet(SOURCE_SHEET_NAME)
Â  Â  except gspread.exceptions.WorksheetNotFound:
Â  Â  Â  Â  ws = sh.add_worksheet(title=SOURCE_SHEET_NAME, rows="3000", cols=str(len(YAHOO_SHEET_HEADERS)))
Â  Â  Â  Â Â 
Â  Â  current_headers = ws.row_values(1)
Â  Â  if current_headers != YAHOO_SHEET_HEADERS:
Â  Â  Â  Â  ws.update(range_name=f'A1:{gspread.utils.rowcol_to_a1(1, len(YAHOO_SHEET_HEADERS))}', values=[YAHOO_SHEET_HEADERS])
Â  Â  return ws

def write_and_sort_news_list_to_source(gc: gspread.Client, articles: list[dict]):
Â  Â  """ â‘  Yahooã‚·ãƒ¼ãƒˆã«è¨˜äº‹ã‚’è¿½è¨˜ã—ã€â‘¡ å¤ã„é †ã«ä¸¦ã³æ›¿ãˆã‚‹ """
Â  Â Â 
Â  Â  sh = gc.open_by_key(SOURCE_SPREADSHEET_ID)
Â  Â  worksheet = ensure_source_sheet_headers(sh)
Â  Â  Â  Â  Â  Â Â 
Â  Â  existing_data = worksheet.get_all_values(value_render_option='UNFORMATTED_VALUE')
Â  Â  existing_urls = set(row[0] for row in existing_data[1:] if len(row) > 0)Â 
Â  Â Â 
Â  Â  new_data = [[a['URL'], a['ã‚¿ã‚¤ãƒˆãƒ«'], a['æŠ•ç¨¿æ—¥æ™‚'], a['ã‚½ãƒ¼ã‚¹']] for a in articles if a['URL'] not in existing_urls]
Â  Â Â 
Â  Â  if new_data:
Â  Â  Â  Â  worksheet.append_rows(new_data, value_input_option='USER_ENTERED')
Â  Â  Â  Â  print(f" SOURCEã‚·ãƒ¼ãƒˆã« {len(new_data)} ä»¶è¿½è¨˜ã—ã¾ã—ãŸã€‚")
Â  Â  Â  Â Â 
Â  Â  Â  Â  all_values = worksheet.get_all_values()
Â  Â  Â  Â  header = all_values[0]
Â  Â  Â  Â  rows = all_values[1:]
Â  Â  Â  Â Â 
Â  Â  Â  Â  now = jst_now()
Â  Â  Â  Â  def sort_key(row):
Â  Â  Â  Â  Â  Â  if len(row) > 2:
Â  Â  Â  Â  Â  Â  Â  Â  dt = parse_post_date(row[2], now)
Â  Â  Â  Â  Â  Â  Â  Â  return dt if dt else datetime.max.replace(tzinfo=TZ_JST)Â 
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  return datetime.max.replace(tzinfo=TZ_JST)
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  sorted_rows = sorted(rows, key=sort_key)Â 
Â  Â  Â  Â Â 
Â  Â  Â  Â  full_data_to_write = [header] + sorted_rows
Â  Â  Â  Â  range_end = gspread.utils.rowcol_to_a1(len(full_data_to_write), len(YAHOO_SHEET_HEADERS))
Â  Â  Â  Â Â 
Â  Â  Â  Â  # ä¸¦ã³æ›¿ãˆãŸãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒ¼ãƒˆã«æ›¸ãæˆ»ã™
Â  Â  Â  Â  worksheet.update(values=full_data_to_write, range_name=f'A1:{range_end}', value_input_option='USER_ENTERED')
Â  Â  Â  Â Â 
Â  Â  Â  Â  print(" SOURCEã‚·ãƒ¼ãƒˆã‚’æŠ•ç¨¿æ—¥æ™‚ã®å¤ã„é †ã«ä¸¦ã³æ›¿ãˆã¾ã—ãŸã€‚")
Â  Â  else:
Â  Â  Â  Â  print(" SOURCEã‚·ãƒ¼ãƒˆã«è¿½è¨˜ã™ã¹ãæ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")


def process_and_update_yahoo_sheet(gc: gspread.Client):
Â  Â  """ Eï½Iåˆ—ãŒæœªå…¥åŠ›ã®è¡Œã«å¯¾ã—ã€è©³ç´°å–å¾—ã¨Geminiåˆ†æã‚’å®Ÿè¡Œã™ã‚‹ """
Â  Â Â 
Â  Â  sh = gc.open_by_key(SOURCE_SPREADSHEET_ID)
Â  Â  ws = sh.worksheet(SOURCE_SHEET_NAME)
Â  Â Â 
Â  Â  all_values = ws.get_all_values(value_render_option='UNFORMATTED_VALUE')
Â  Â  if len(all_values) <= 1:
Â  Â  Â  Â  print(" Yahooã‚·ãƒ¼ãƒˆã«ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚ã€è©³ç´°å–å¾—ãƒ»åˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
Â  Â  Â  Â  return
Â  Â  Â  Â Â 
Â  Â  data_rows = all_values[1:]
Â  Â  updates_dict: Dict[int, List[Any]] = {}Â 
Â  Â Â 
Â  Â  for idx, data_row in enumerate(data_rows):
Â  Â  Â  Â  row_num = idx + 2Â 
Â  Â  Â  Â Â 
Â  Â  Â  Â  url = data_row[0] if len(data_row) > 0 else ""Â 
Â  Â  Â  Â Â 
Â  Â  Â  Â  # ç¾åœ¨ã®E-Iåˆ—ã®å€¤ã‚’å–å¾—
Â  Â  Â  Â  body = data_row[4] if len(data_row) > 4 else ""Â 
Â  Â  Â  Â  comment_count = data_row[5] if len(data_row) > 5 else ""Â 
Â  Â  Â  Â  sentiment = data_row[6] if len(data_row) > 6 else ""
Â  Â  Â  Â  category = data_row[7] if len(data_row) > 7 else ""
Â  Â  Â  Â  relevance = data_row[8] if len(data_row) > 8 else ""

Â  Â  Â  Â  # ãƒ•ãƒ©ã‚°: æœ¬æ–‡ã¨ã‚³ãƒ¡ãƒ³ãƒˆæ•°ãŒå¿…è¦ã‹
Â  Â  Â  Â  needs_details = not body.strip() or not str(comment_count).strip()
Â  Â  Â  Â Â 
Â  Â  Â  Â  # ãƒ•ãƒ©ã‚°: Geminiåˆ†æãŒå¿…è¦ã‹
Â  Â  Â  Â  needs_analysis = not str(sentiment).strip() or not str(category).strip() or not str(relevance).strip()

Â  Â  Â  Â  # ã‚¹ã‚­ãƒƒãƒ—æ¡ä»¶: æœ¬æ–‡ãŒæ—¢ã«å…¥ã£ã¦ã„ã¦ã€ã‹ã¤åˆ†æçµæœã‚‚ã™ã¹ã¦å…¥ã£ã¦ã„ã‚‹å ´åˆã®ã¿
Â  Â  Â  Â  if not needs_details and not needs_analysis:
Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  if not url.strip():
Â  Â  Â  Â  Â  Â  print(f"Â  - è¡Œ {row_num}: URLãŒãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã€‚")
Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  title = data_row[1] if len(data_row) > 1 else "ä¸æ˜"
Â  Â  Â  Â  print(f"Â  - è¡Œ {row_num} (è¨˜äº‹: {title[:20]}...): å‡¦ç†ã‚’å®Ÿè¡Œä¸­...")

Â  Â  Â  Â  # 1. æœ¬æ–‡ã¨ã‚³ãƒ¡ãƒ³ãƒˆæ•°ã®å–å¾— (E, Fåˆ—)
Â  Â  Â  Â  article_body = body
Â  Â  Â  Â  final_comment_count = comment_count
Â  Â  Â  Â Â 
Â  Â  Â  Â  if needs_details or not article_body.strip(): # æœ¬æ–‡ãŒç©ºã‹ã€è©³ç´°å–å¾—ãŒå¿…è¦ãªå ´åˆ
Â  Â  Â  Â  Â  Â  fetched_body, fetched_comment_count = fetch_article_body_and_comments(url)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if not article_body.strip():
Â  Â  Â  Â  Â  Â  Â  Â  article_body = fetched_body
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if not str(final_comment_count).strip() or str(final_comment_count).strip() == '0':
Â  Â  Â  Â  Â  Â  Â  Â  final_comment_count = fetched_comment_count
Â  Â  Â  Â Â 
Â  Â  Â  Â Â 
Â  Â  Â  Â  # 2. Geminiã§åˆ†æã‚’å®Ÿè¡Œ (G, H, Iåˆ—)
Â  Â  Â  Â  final_sentiment = sentiment
Â  Â  Â  Â  final_category = category
Â  Â  Â  Â  final_relevance = relevance

Â  Â  Â  Â  if needs_analysis and article_body.strip(): # æœ¬æ–‡ãŒã‚ã‚Šã€åˆ†æãŒå¿…è¦ãªå ´åˆ
Â  Â  Â  Â  Â  Â  final_sentiment, final_category, final_relevance = analyze_with_gemini(article_body)
Â  Â  Â  Â  Â  Â  time.sleep(1 + random.random() * 0.5) # APIè² è·è»½æ¸›ã®ãŸã‚ã®å¾…æ©Ÿ
Â  Â  Â  Â  elif needs_analysis and not article_body.strip():
Â  Â  Â  Â  Â  Â  Â # æœ¬æ–‡ãŒå–ã‚Œãªã‹ã£ãŸãŒåˆ†æãŒå¿…è¦ãªå ´åˆï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ¼ã‚¯ï¼‰
Â  Â  Â  Â  Â  Â  Â final_sentiment, final_category, final_relevance = "N/A(No Body)", "N/A", "0"

Â  Â  Â  Â Â 
Â  Â  Â  Â  # 3. æ›´æ–°ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
Â  Â  Â  Â  new_body = article_body if not body.strip() else body
Â  Â  Â  Â  new_comment_count = final_comment_count if not str(comment_count).strip() or str(comment_count).strip() == '0' else comment_count

Â  Â  Â  Â  if needs_analysis and article_body.strip():
Â  Â  Â  Â  Â  Â  Â new_sentiment = final_sentiment
Â  Â  Â  Â  Â  Â  Â new_category = final_category
Â  Â  Â  Â  Â  Â  Â new_relevance = final_relevance
Â  Â  Â  Â  elif needs_analysis and not article_body.strip():
Â  Â  Â  Â  Â  Â  Â new_sentiment = final_sentiment 
Â  Â  Â  Â  Â  Â  Â new_category = final_category 
Â  Â  Â  Â  Â  Â  Â new_relevance = final_relevance 
Â  Â  Â  Â  else: # åˆ†æãŒå¿…è¦ãªã„å ´åˆã¯æ—¢å­˜å€¤ã‚’ä¿æŒ
Â  Â  Â  Â  Â  Â  Â new_sentiment = sentiment
Â  Â  Â  Â  Â  Â  Â new_category = category
Â  Â  Â  Â  Â  Â  Â new_relevance = relevance

Â  Â  Â  Â  # æœ€çµ‚çš„ãªæ›´æ–°ãƒ‡ãƒ¼ã‚¿
Â  Â  Â  Â  updates_dict[row_num] = [new_body, new_comment_count, new_sentiment, new_category, new_relevance]


Â  Â  if updates_dict:
Â  Â  Â  Â  updates_list = []
Â  Â  Â  Â  rows_to_update = sorted(updates_dict.keys())
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Eåˆ—ã‹ã‚‰Iåˆ—ã¾ã§ã‚’ä¸€æ‹¬ã§æ›´æ–°
Â  Â  Â  Â  for r_num in rows_to_update:
Â  Â  Â  Â  Â  Â  range_name = f'E{r_num}:I{r_num}'Â 
Â  Â  Â  Â  Â  Â  updates_list.append({
Â  Â  Â  Â  Â  Â  Â  Â  'range': range_name,
Â  Â  Â  Â  Â  Â  Â  Â  'values': [updates_dict[r_num]] 
Â  Â  Â  Â  Â  Â  })
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  ws.batch_update(updates_list, value_input_option='USER_ENTERED')
Â  Â  Â  Â  print(f" Yahooã‚·ãƒ¼ãƒˆã® {len(updates_dict)} è¡Œã®E-Iåˆ—ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚")
Â  Â  else:
Â  Â  Â  Â  print(" Yahooã‚·ãƒ¼ãƒˆã§æ–°ãŸã«å–å¾—ãƒ»åˆ†æã™ã¹ãç©ºæ¬„ã®è¡Œã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")


# ====== ãƒ¡ã‚¤ãƒ³å‡¦ç† ======

def main():
Â  Â  print("--- çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆé–‹å§‹ ---")
Â  Â Â 
Â  Â  try:
Â  Â  Â  Â  gc = build_gspread_client()
Â  Â  except RuntimeError as e:
Â  Â  Â  Â  print(f"è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: {e}")
Â  Â  Â  Â  return
Â  Â Â 
Â  Â  # 1. Yahooã‚·ãƒ¼ãƒˆã«è¨˜äº‹ãƒªã‚¹ãƒˆã‚’è¿½è¨˜ã—ã€æŠ•ç¨¿æ—¥ã®å¤ã„é †ã«ä¸¦ã³æ›¿ãˆ
Â  Â  yahoo_news_articles = get_yahoo_news_with_selenium(KEYWORD)
Â  Â  write_and_sort_news_list_to_source(gc, yahoo_news_articles)
Â  Â Â 
Â  Â  # 2. Yahooã‚·ãƒ¼ãƒˆã®E-Iåˆ—ã«å¯¾ã—ã€æœ¬æ–‡ã€ã‚³ãƒ¡ãƒ³ãƒˆæ•°ã€Geminiåˆ†æã‚’å®Ÿè¡Œã—ã€ç©ºæ¬„ãŒã‚ã‚Œã°æ›´æ–°ã€‚
Â  Â  process_and_update_yahoo_sheet(gc)
Â  Â Â 
Â  Â  # â˜… å‰Šé™¤æ¸ˆã¿: 3. å½“æ—¥ã‚·ãƒ¼ãƒˆã‚’ä½œæˆã—ã€Yahooã‚·ãƒ¼ãƒˆã‹ã‚‰å¯¾è±¡æœŸé–“ã®å…¨è¨˜äº‹ï¼ˆA-Iåˆ—ï¼‰ã‚’ã‚³ãƒ”ãƒ¼ã€‚

Â  Â  print("\n--- çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆçµ‚äº† ---")

if __name__ == "__main__":
Â  Â  main()
